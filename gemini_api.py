import os
import json
import google.generativeai as genai
from dotenv import load_dotenv

# Load environment variables
load_dotenv()

# Configure the Gemini API
genai.configure(api_key=os.getenv("GEMINI_API_KEY"))

# Set up the model
model = genai.GenerativeModel('gemini-2.0-flash')

def get_response(prompt, data=None):
    """
    Get a response from Gemini API based on the provided prompt and data.
    
    Args:
        prompt (str): The user's question or prompt
        data (dict, optional): Additional data to provide context
        
    Returns:
        str: The response from Gemini
    """
    try:
        # If data is provided, include it in the context
        if data:
            data_context = json.dumps(data, indent=2)
            full_prompt = f"""
            Basado en los siguientes datos:
            
            {data_context}
            
            Responde a esta pregunta de manera concisa y directa:
            {prompt}
            
            Proporciona solo hechos basados en los datos proporcionados.
            """
        else:
            full_prompt = prompt
        
        # Generate response
        response = model.generate_content(full_prompt)
        return response.text
    except Exception as e:
        return f"Error al consultar a Gemini: {str(e)}"

def get_data_insights(warehouses, products, stores):
    """
    Generate insights about the data.
    
    Args:
        warehouses (list): Warehouse data
        products (list): Product data
        stores (list): Store data
        
    Returns:
        str: Insights generated by Gemini
    """
    # Prepare a summary of the data for Gemini
    warehouse_summary = {
        "total_warehouses": len(warehouses),
        "countries": list(set(w["country"] for w in warehouses)),
        "sample_warehouse": warehouses[0] if warehouses else None
    }
    
    product_summary = {
        "total_products": len(products),
        "brands": list(set(p["brandId"] for p in products)),
        "sample_product": products[0] if products else None
    }
    
    store_summary = {
        "total_stores": len(stores)
    }
    
    # Create context for Gemini
    data_summary = {
        "warehouses": warehouse_summary,
        "products": product_summary,
        "stores": store_summary
    }
    
    prompt = """
    Analiza los datos proporcionados sobre almacenes, productos y tiendas de Inditex.
    Proporciona 3 insights importantes sobre la distribución de productos, 
    almacenes y posibles oportunidades de optimización.
    """
    
    return get_response(prompt, data_summary)

print(get_response("Explain how AI works in a few words"))